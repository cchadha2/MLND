{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_and_test():\n",
    "    \n",
    "    application_train = pd.read_csv('data/application_train.csv')\n",
    "    application_test = pd.read_csv('data/application_test.csv')\n",
    "    \n",
    "    application_train = application_train.sort_values(by = 'SK_ID_CURR')\n",
    "    application_test = application_test.sort_values(by = 'SK_ID_CURR')\n",
    "    df = application_train.append(application_test).reset_index()\n",
    "\n",
    "    df['DAYS_EMPLOYED_MISS'] = df['DAYS_EMPLOYED'] == 365243\n",
    "    df['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "    binary_features = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "                       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'REG_REGION_NOT_LIVE_REGION',\n",
    "                       'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', \n",
    "                       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', \n",
    "                       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
    "                       'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', \n",
    "                       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "                       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "                       'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'DAYS_EMPLOYED_MISS']\n",
    "    for feature in binary_features:\n",
    "        df[feature], uniques = pd.factorize(df[feature])\n",
    "\n",
    "    df, df_cat_col = one_hot_encoder(df)\n",
    "    df = df.drop('index', axis=1)\n",
    "    \n",
    "    del application_train\n",
    "    del application_test\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(df):\n",
    "    \n",
    "    bureau = pd.read_csv('data/bureau.csv')\n",
    "    bureau_balance = pd.read_csv('data/bureau_balance.csv')\n",
    "    \n",
    "    previous_loans = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loans'})\n",
    "    df = df.merge(previous_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['previous_loans'] = df['previous_loans'].fillna(0)\n",
    "    \n",
    "    closed_loans = bureau[bureau['CREDIT_ACTIVE'] == 'Closed']\n",
    "    closed_loans = closed_loans.groupby('SK_ID_CURR', as_index=False)['CREDIT_ACTIVE'].count().rename(columns = {'CREDIT_ACTIVE': 'closed_loans'})\n",
    "    df = df.merge(closed_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['closed_loans'] = df['closed_loans'].fillna(0)\n",
    "    active_loans = bureau[bureau['CREDIT_ACTIVE'] == 'Active']\n",
    "    active_loans = active_loans.groupby('SK_ID_CURR', as_index=False)['CREDIT_ACTIVE'].count().rename(columns = {'CREDIT_ACTIVE': 'active_loans'})\n",
    "    df = df.merge(active_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['active_loans'] = df['active_loans'].fillna(0)\n",
    "    \n",
    "    bureau, bureau_cat_cols = one_hot_encoder(bureau)\n",
    "    bureau_balance, bureau_balance_cat_cols = one_hot_encoder(bureau_balance)\n",
    "\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({'DAYS_CREDIT':['min', 'max', 'mean'],\n",
    "                                                   'CREDIT_DAY_OVERDUE':['max', 'mean'],\n",
    "                                                   'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "                                                   'DAYS_ENDDATE_FACT': ['mean'],\n",
    "                                                   'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "                                                   'CNT_CREDIT_PROLONG': ['count'],\n",
    "                                                   'AMT_CREDIT_SUM': ['min', 'max', 'mean'],\n",
    "                                                   'AMT_CREDIT_SUM_DEBT': ['min', 'max', 'mean'],\n",
    "                                                   'AMT_CREDIT_SUM_LIMIT': ['sum', 'mean'],\n",
    "                                                   'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "                                                   'DAYS_CREDIT_UPDATE': ['min', 'max', 'mean'],\n",
    "                                                   'AMT_ANNUITY': ['max', 'mean']})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    df = df.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    bureau_balance_and_bureau = bureau.merge(bureau_balance, on = 'SK_ID_BUREAU', how = 'left')\n",
    "    bureau_balance_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bureau_balance_cat_cols:\n",
    "        bureau_balance_aggregations[col] = ['mean']\n",
    "    bureau_balance_agg = bureau_balance_and_bureau.groupby('SK_ID_CURR').agg(bureau_balance_aggregations)\n",
    "    bureau_balance_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bureau_balance_agg.columns.tolist()])\n",
    "    for row in range(len(bureau_balance_agg)):\n",
    "        if np.isnan(bureau_balance_agg.iloc[row, 0]) == True and np.isnan(bureau_balance_agg.iloc[row, 1]) == True:\n",
    "            bureau_balance_agg.iloc[row, 2] = np.nan\n",
    "\n",
    "    df = df.merge(bureau_balance_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del bureau\n",
    "    del bureau_balance\n",
    "    del bureau_agg\n",
    "    del previous_loans\n",
    "    del closed_loans\n",
    "    del active_loans\n",
    "    del bureau_balance_and_bureau\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_balance(df):\n",
    "    \n",
    "    credit_card_balance = pd.read_csv('data/credit_card_balance.csv')\n",
    "    \n",
    "    prev_credit_months = credit_card_balance.groupby(['SK_ID_CURR', 'SK_ID_PREV'], as_index=False)['MONTHS_BALANCE'].count().rename(columns = {'MONTHS_BALANCE': 'prev_credit_months'})\n",
    "    prev_credit_months['prev_credit_months'] = -prev_credit_months['prev_credit_months']\n",
    "    previous_credit_loans = pd.DataFrame()\n",
    "    previous_credit_loans['SK_ID_CURR'] = prev_credit_months['SK_ID_CURR'].value_counts().index.values\n",
    "    previous_credit_loans['previous_credit_loans'] = prev_credit_months['SK_ID_CURR'].value_counts().values\n",
    "    df = df.merge(previous_credit_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['previous_credit_loans'] = df['previous_credit_loans'].fillna(0)\n",
    "    \n",
    "    current_loan_status = credit_card_balance[['SK_ID_CURR', 'SK_ID_PREV', 'NAME_CONTRACT_STATUS']].sort_values(by = ['SK_ID_CURR', 'NAME_CONTRACT_STATUS']).drop_duplicates()\n",
    "    current_loan_status = current_loan_status[current_loan_status['NAME_CONTRACT_STATUS'].isin(['Active', 'Completed'])]\n",
    "    \n",
    "    prev_credit_completed = current_loan_status[current_loan_status['NAME_CONTRACT_STATUS'] == 'Completed']\n",
    "    prev_credit_completed = pd.get_dummies(prev_credit_completed)\n",
    "    del prev_credit_completed['SK_ID_PREV']\n",
    "    prev_credit_completed = prev_credit_completed.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Completed'].count()\n",
    "    df = df.merge(prev_credit_completed, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Completed'] = df['NAME_CONTRACT_STATUS_Completed'].fillna(0)\n",
    "    \n",
    "    prev_credit_active = current_loan_status.drop_duplicates(subset = ['SK_ID_CURR', 'SK_ID_PREV'], keep = False)\n",
    "    prev_credit_active = prev_credit_active[prev_credit_active['NAME_CONTRACT_STATUS'] == 'Active']\n",
    "    prev_credit_active = pd.get_dummies(prev_credit_active)\n",
    "    del prev_credit_active['SK_ID_PREV']\n",
    "    prev_credit_active = prev_credit_active.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Active'].count()\n",
    "    df = df.merge(prev_credit_active, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Active'] = df['NAME_CONTRACT_STATUS_Active'].fillna(0)\n",
    "        \n",
    "    credit_card_balance.drop(columns = ['NAME_CONTRACT_STATUS', 'SK_ID_PREV'], inplace = True)\n",
    "    credit_card_balance, credit_card_balance_cat_cols = one_hot_encoder(credit_card_balance)\n",
    "    \n",
    "    cc_agg = credit_card_balance.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    \n",
    "    df = df.merge(cc_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del credit_card_balance\n",
    "    del prev_credit_months\n",
    "    del previous_credit_loans\n",
    "    del current_loan_status\n",
    "    del prev_credit_completed\n",
    "    del prev_credit_active\n",
    "    del cc_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments(df):\n",
    "    \n",
    "    installments_payments = pd.read_csv('data/installments_payments.csv')\n",
    "\n",
    "    installments_day_diff = installments_payments.sort_values(by = ['SK_ID_CURR', 'SK_ID_PREV'])[['SK_ID_CURR', 'SK_ID_PREV', 'DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT']]\n",
    "    installments_day_diff['installments_day_diff'] = installments_day_diff['DAYS_INSTALMENT'] - installments_day_diff['DAYS_ENTRY_PAYMENT']\n",
    "    installments_day_diff_agg = installments_day_diff.groupby(['SK_ID_CURR', 'SK_ID_PREV'], as_index=False)['installments_day_diff'].mean()\n",
    "    del installments_day_diff_agg['SK_ID_PREV']\n",
    "    \n",
    "    installments_day_diff_agg = installments_day_diff_agg.groupby('SK_ID_CURR', as_index=False)['installments_day_diff'].mean()\n",
    "    df = df.merge(installments_day_diff_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    del installments_payments['DAYS_INSTALMENT']\n",
    "    del installments_payments['DAYS_ENTRY_PAYMENT']\n",
    "\n",
    "    installments_diff = installments_payments.sort_values(by = ['SK_ID_CURR', 'SK_ID_PREV'])[['SK_ID_CURR', 'SK_ID_PREV', 'AMT_INSTALMENT', 'AMT_PAYMENT']]\n",
    "    installments_diff['installments_diff'] = installments_diff['AMT_INSTALMENT'] - installments_diff['AMT_PAYMENT']\n",
    "    installments_diff_agg = installments_diff.groupby(['SK_ID_CURR', 'SK_ID_PREV'], as_index=False)['installments_diff'].mean()\n",
    "    installments_diff_agg.head()\n",
    "    del installments_diff_agg['SK_ID_PREV']\n",
    "\n",
    "    installments_diff_agg = installments_diff_agg.groupby('SK_ID_CURR', as_index=False)['installments_diff'].mean()\n",
    "    df = df.merge(installments_diff_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del installments_payments\n",
    "    del installments_day_diff\n",
    "    del installments_day_diff_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(df):\n",
    "    \n",
    "    POS_CASH_balance = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "\n",
    "    prev_POS_months = POS_CASH_balance.groupby(['SK_ID_CURR', 'SK_ID_PREV'], as_index=False)['MONTHS_BALANCE'].count().rename(columns = {'MONTHS_BALANCE': 'prev_POS_months'})\n",
    "    prev_POS_months['prev_POS_months'] = -prev_POS_months['prev_POS_months']\n",
    "    previous_POS_loans = pd.DataFrame()\n",
    "    previous_POS_loans['SK_ID_CURR'] = prev_POS_months['SK_ID_CURR'].value_counts().index.values\n",
    "    previous_POS_loans['previous_POS_loans'] = prev_POS_months['SK_ID_CURR'].value_counts().values\n",
    "    df = df.merge(previous_POS_loans, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['previous_POS_loans'] = df['previous_POS_loans'].fillna(0)\n",
    "\n",
    "    current_POS_status = POS_CASH_balance[['SK_ID_CURR', 'SK_ID_PREV', 'NAME_CONTRACT_STATUS']].sort_values(by = ['SK_ID_CURR', 'NAME_CONTRACT_STATUS']).drop_duplicates()\n",
    "    current_POS_status = current_POS_status[current_POS_status['NAME_CONTRACT_STATUS'].isin(['Active', 'Completed'])]\n",
    "\n",
    "    prev_POS_completed = current_POS_status[current_POS_status['NAME_CONTRACT_STATUS'] == 'Completed']\n",
    "    prev_POS_completed = pd.get_dummies(prev_POS_completed)\n",
    "    del prev_POS_completed['SK_ID_PREV']\n",
    "    prev_POS_completed = prev_POS_completed.rename(columns = {'NAME_CONTRACT_STATUS_Completed': 'NAME_CONTRACT_STATUS_Completed_POS'})\n",
    "    prev_POS_completed = prev_POS_completed.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Completed_POS'].count()\n",
    "    df = df.merge(prev_POS_completed, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Completed_POS'] = df['NAME_CONTRACT_STATUS_Completed_POS'].fillna(0)\n",
    "\n",
    "    prev_POS_active = current_POS_status.drop_duplicates(subset = ['SK_ID_CURR', 'SK_ID_PREV'], keep = False)\n",
    "    prev_POS_active = prev_POS_active[prev_POS_active['NAME_CONTRACT_STATUS'] == 'Active']\n",
    "    prev_POS_active = pd.get_dummies(prev_POS_active)\n",
    "    del prev_POS_active['SK_ID_PREV']\n",
    "    prev_POS_active = prev_POS_active.rename(columns = {'NAME_CONTRACT_STATUS_Active': 'NAME_CONTRACT_STATUS_Active_POS'})\n",
    "    prev_POS_active = prev_POS_active.groupby('SK_ID_CURR', as_index=False)['NAME_CONTRACT_STATUS_Active_POS'].count()\n",
    "    df = df.merge(prev_POS_active, on = 'SK_ID_CURR', how = 'left')\n",
    "    df['NAME_CONTRACT_STATUS_Active_POS'] = df['NAME_CONTRACT_STATUS_Active_POS'].fillna(0)\n",
    "\n",
    "    POS_CASH_balance.drop(columns = ['NAME_CONTRACT_STATUS', 'SK_ID_PREV'], inplace = True) \n",
    "    POS_CASH_balance_agg = POS_CASH_balance.groupby('SK_ID_CURR').agg(['min', 'max', 'mean'])\n",
    "    POS_CASH_balance_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in POS_CASH_balance_agg.columns.tolist()])\n",
    "    \n",
    "    df = df.merge(POS_CASH_balance_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del prev_POS_months\n",
    "    del previous_POS_loans\n",
    "    del current_POS_status\n",
    "    del prev_POS_completed\n",
    "    del prev_POS_active\n",
    "    del POS_CASH_balance\n",
    "    del POS_CASH_balance_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_app(df):\n",
    "\n",
    "    previous_application = pd.read_csv('data/previous_application.csv')\n",
    "\n",
    "    previous_application['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    previous_application['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "    previous_application, cat_cols = one_hot_encoder(previous_application)\n",
    "    \n",
    "    num_aggregations = {'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "                        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "                        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "                        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "                        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "                        'HOUR_APPR_PROCESS_START': ['mean', 'median'],\n",
    "                        'NFLAG_LAST_APPL_IN_DAY': ['mean', 'size'],\n",
    "                        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "                        'RATE_INTEREST_PRIMARY': ['min', 'max', 'mean'],\n",
    "                        'RATE_INTEREST_PRIVILEGED': ['min', 'max', 'mean'],\n",
    "                        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "                        'CNT_PAYMENT': ['sum', 'mean']}\n",
    "\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "\n",
    "    prev_agg = previous_application.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "    approved = previous_application[previous_application['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APR_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    refused = previous_application[previous_application['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REF_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    df = df.merge(prev_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "    \n",
    "    del previous_application\n",
    "    del prev_agg\n",
    "    del approved\n",
    "    del approved_agg\n",
    "    del refused\n",
    "    del refused_agg\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances-01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, num_folds, stratified = False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    # This is not handling multi-level indexing correctly\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=34,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.041545473,\n",
    "            reg_lambda=0.0735294,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 100)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/home-credit/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (356255, 299)\n",
      "Process bureau and bureau_balance - done in 98s\n",
      "df shape: (356255, 402)\n",
      "Process credit card balance - done in 28s\n",
      "df shape: (356255, 404)\n",
      "Process installments payments - done in 33s\n",
      "df shape: (356255, 422)\n",
      "Process POS_CASH_balance - done in 27s\n",
      "df shape: (356255, 680)\n",
      "Process previous_applications - done in 45s\n",
      "Starting LightGBM. Train shape: (307511, 680), test shape: (48744, 680)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.772002\tvalid_1's auc: 0.755761\n",
      "[200]\ttraining's auc: 0.794438\tvalid_1's auc: 0.770764\n",
      "[300]\ttraining's auc: 0.807579\tvalid_1's auc: 0.777477\n",
      "[400]\ttraining's auc: 0.817184\tvalid_1's auc: 0.780922\n",
      "[500]\ttraining's auc: 0.82528\tvalid_1's auc: 0.782994\n",
      "[600]\ttraining's auc: 0.832569\tvalid_1's auc: 0.78421\n",
      "[700]\ttraining's auc: 0.838993\tvalid_1's auc: 0.784874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-904773e54962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msubmission_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"submission_chirag.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full model run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-904773e54962>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run LightGBM with kfold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-155054d8b831>\u001b[0m in \u001b[0;36mkfold_lightgbm\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n\u001b[0;32m---> 42\u001b[0;31m             eval_metric= 'auc', verbose= 100, early_stopping_rounds= 100)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moof_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/home-credit/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = application_train_and_test()\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        df = bureau_and_balance(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        df = cc_balance(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process installments payments\"):\n",
    "        df = installments(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process POS_CASH_balance\"):\n",
    "        df = pos_cash(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        df = prev_app(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "\n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 5, stratified = True)\n",
    "        \n",
    "    return df, feat_importance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    submission_file_name = \"predictions/lightgbm_pred.csv\"\n",
    "    with timer(\"Full model run\"):\n",
    "        df, feat_importance = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use feature importances graph to focus data preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
